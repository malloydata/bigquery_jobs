>>>markdown
# INFORMATION_SCHEMA Job views
Creates dataset `jobs_views` based on INFORMATION_SCHEMA.JOBS withthe following views:

* **jobs_views.query_analysis** - Grouped by unique query.  Shows various totals, uses and caching.
* **jobs_views.by_dataset_date** - Rollup by dataset and date
* **jobs_views.by_table_date** - Rollup by table and date
* **jobs_views.by_email_date** - Rollup by email and date

`Run All` to create the views.  Re-running will update the views with new specifications.
>>>malloy
import "jobs.malloy"

source: jobs_views is jobs extend {
    // # view='query_analysis'
  view: query_analysis is by_query + {
    group_by: sql_query
    aggregate: 
      max_slot_seconds is max(slot_seconds)
      average_slot_seconds is avg(slot_seconds)
    nest: referenced_tables is {
      group_by: 
        referenced_tables.dataset_id
        referenced_tables.table_id
    }
  }

  view: by_date_fields is {
    group_by: 
      query_date is start_time::date
      is_service_account
  } 

  view: by_date is by_date_fields + metrics

  view: email_date is  by_date_fields + {
    where: user_email != null
    group_by: user_email
  } + metrics

  view: dataset_date is by_date_fields +  {
    where: referenced_tables.dataset_id != null
    group_by: referenced_tables.dataset_id
  } + metrics

  view: table_date is by_date_fields + {
    where: referenced_tables.table_id != null
    group_by: 
      referenced_tables.dataset_id
      referenced_tables.table_id
  } + metrics
} 
>>>markdown
### SQL Commands to create the views.
They are listed separately so they can be individually tested.
>>>sql
-- connection: bigquery
create schema if not exists jobs_views 
>>>sql
create or replace view job_views.by_email_date as %{jobs_views->email_date}%
>>>sql
create or replace view job_views.by_dataset_date as %{jobs_views->dataset_date}%  
>>>sql
create or replace view job_views.by_table_date as %{jobs_views->table_date}%
>>>sql
create or replace view job_views.query_analysis as %{jobs_views->query_analysis}%
